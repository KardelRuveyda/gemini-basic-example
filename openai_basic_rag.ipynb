{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52602e2",
   "metadata": {},
   "source": [
    "## PDF YÃ¼klemesinin GerÃ§ekleÅŸtirlimesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c057c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruveyda.cetin\\AppData\\Local\\miniconda3\\envs\\rag_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"calikusu.pdf\")\n",
    "data = loader.load()\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "969a0585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a01597",
   "metadata": {},
   "source": [
    "## Veriyi parÃ§alara ayÄ±rma(Chunking iÅŸlemi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a377a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 537\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Daha bÃ¼yÃ¼k chunk size kullan (daha az chunk = daha az token)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,  # 1000'den 2000'e Ã§Ä±kar\n",
    "    chunk_overlap=200  # Overlap ekle (context korunmasÄ± iÃ§in)\n",
    ")\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "print(f\"Total chunks: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bbeff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents after chunking: 537\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of documents after chunking: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a49e7284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'calibre 1.22.0 [http://calibre-ebook.com]', 'creator': 'calibre 1.22.0 [http://calibre-ebook.com]', 'creationdate': '2018-06-07T15:24:58+00:00', 'author': 'ReÅŸat Nuri GÃ¼ntekin', 'keywords': 'Roman, TÃ¼rk Klasik, Cumhuriyet DÃ¶nemi', 'title': 'Ã‡alÄ±kuÅŸu', 'source': 'calikusu.pdf', 'total_pages': 298, 'page': 7, 'page_label': '8'}, page_content='SÃ¶r Aleksi, izahatÄ±nÄ± bitirdikten sonra bizi Ã§alÄ±ÅŸmaya bÄ±rakmÄ±ÅŸtÄ±.\\nÃ–n sÄ±ralarÄ± sÃ¼sleyen aÄŸÄ±rbaÅŸlÄ± sÄ±nÄ±f birincileri hemen iÅŸe koyulmuÅŸlardÄ±. YanlarÄ±nda olmadÄ±ÄŸÄ±m\\nhalde ne yazdÄ±klarÄ±nÄ± omuzlarÄ± Ã¼zerinden okumuÅŸ gibi biliyordum: â€œÄ°lk hÃ¢tÄ±ranÄ±, sevgili anneciÄŸimin\\nkÃ¼Ã§Ã¼k karyolamÄ±n Ã¼stÃ¼ne eÄŸilen mÃ¼ÅŸfik altÄ±n sarÄ±sÄ± baÅŸÄ±, bana muhabbetle gÃ¼lÃ¼mseyen gÃ¶k mavisi\\ngÃ¶zleridir,â€ tarzÄ±nda ÅŸairane bir yalancÄ±lÄ±k... Hakikatte annecikler altÄ±n sarÄ±sÄ± ve gÃ¶k mavisinden\\nbaÅŸka renklerde de olabilirdi. Fakat sÃ¶rlerde okuyan kÄ±zlarÄ±n kaleminden bu renklere boyanmak, o\\nbiÃ§areler iÃ§in bir mecburiyet, bizim iÃ§in bir usuldÃ¼.\\nBana gelince, ben bambaÅŸka bir Ã§ocuktum. Ã‡ok kÃ¼Ã§Ã¼k yaÅŸta kaybettiÄŸim annemden aklÄ±mda pek\\nfazla bir ÅŸey kalmamÄ±ÅŸtÄ±. Fakat herhalde altÄ±n saÃ§lÄ± ve mavi gÃ¶zlÃ¼ olmadÄ±ÄŸÄ± muhakkaktÄ±. BÃ¶yle olunca\\nda hiÃ§bir kuvvet bana onu asÄ±l Ã§ehresinden baÅŸka bir Ã§ehre ile dÃ¼ÅŸÃ¼ndÃ¼rmeye ve sevdirmeye muktedir\\ndeÄŸildi.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b6c80",
   "metadata": {},
   "source": [
    "## OpenAI AI Embeddings'i Kullanarak Embedding OluÅŸturma Ä°ÅŸlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "651153dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78378ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bc81cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"  # large yerine small\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb7345b",
   "metadata": {},
   "source": [
    "## ChromaDB Ãœzerine KayÄ±t Ä°ÅŸlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f73b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc0f1f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Created 607 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating vector store: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:22<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector store created and persisted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 1. Daha bÃ¼yÃ¼k chunk'lar oluÅŸtur\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150\n",
    ")\n",
    "docs = text_splitter.split_documents(data)\n",
    "print(f\"ğŸ“ Created {len(docs)} chunks\")\n",
    "\n",
    "# 2. Embedding oluÅŸtur\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 3. Batch processing ile vector store oluÅŸtur\n",
    "def create_vector_store_in_batches(docs, embeddings, batch_size=40):\n",
    "    vector_store = None\n",
    "    total_batches = (len(docs) - 1) // batch_size + 1\n",
    "    \n",
    "    for i in tqdm(range(0, len(docs), batch_size), desc=\"Creating vector store\"):\n",
    "        batch = docs[i:i + batch_size]\n",
    "        \n",
    "        if vector_store is None:\n",
    "            vector_store = Chroma.from_documents(\n",
    "                documents=batch,\n",
    "                embedding=embeddings,\n",
    "                persist_directory=\"./chroma_db_openai\"\n",
    "            )\n",
    "        else:\n",
    "            vector_store.add_documents(batch)\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "vector_store = create_vector_store_in_batches(docs, embeddings, batch_size=40)\n",
    "print(\"âœ… Vector store created and persisted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59b17ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af45501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is encoder?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "255c4a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b05baea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mÃ¼zakere etmek: Ã–ÄŸrencilerin ders hazÄ±rlamalarÄ± iÃ§in Ã§alÄ±ÅŸmalarÄ±.\n",
      "mÃ¼zakkere: (MÃ¼zekkere) Bir iÅŸ hakkÄ±nda Ã¼st makama sunulan yazÄ±.\n",
      "mÃ¼zmin: Uzun sÃ¼reli.\n",
      "-N-\n",
      "nadide: Az gÃ¶rÃ¼lÃ¼r, deÄŸerli.\n",
      "nadir: Seyrek, az.\n",
      "nafÃ®a: BayÄ±ndÄ±rlÄ±k.\n",
      "nafile: YararsÄ±z, boÅŸa giden.\n",
      "nalÃ§a: 1) AyakkabÄ±lar Ã§abuk eskimesin diye altÄ±na Ã§akÄ±lan demir. 2) KatÄ±r, eÅŸek, sÄ±ÄŸÄ±r gibi\n",
      "hayvanlarÄ±n tÄ±rnaklarÄ± altÄ±na Ã§akÄ±lan demir parÃ§asÄ±.\n",
      "namÃ¼nasip: Uygun olmayan.\n",
      "nan: Ekmek.\n",
      "nasihat: Ã–ÄŸÃ¼t.\n",
      "nazÄ±n Bakan.\n",
      "nedamet: PiÅŸmanlÄ±k.\n",
      "nefer: Asker.\n",
      "nekahat: HastalÄ±k sonrasÄ± saÄŸlÄ±klÄ± duruma geÃ§me dÃ¶nemi.\n",
      "nekin Bilmezlik.\n",
      "neÅŸretmek: Yaymak.\n",
      "netice itibarÄ±yla: SonuÃ§ olarak.\n",
      "netice: SonuÃ§.\n",
      "nev'i: (Nevi) Ã‡eÅŸit, cins, tÃ¼r.\n",
      "nihayetinde: Sonunda.\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[5].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1580b9c6",
   "metadata": {},
   "source": [
    "## OpenAI API YapÄ±sÄ±nÄ± Kullanarak LLM Tetikleme Ä°ÅŸlemleri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4805eb",
   "metadata": {},
   "source": [
    "- DÃ¼ÅŸÃ¼k DeÄŸerler (0.1-0.4): Daha kesin ve daha tutarlÄ± cevaplar verilir. Model daha tahmin edilebilir hale gelir. \n",
    "- Orta DeÄŸerler(0.5-0.7): Hem mantÄ±klÄ± hem de yaratÄ±cÄ± cevaplar verilir. \n",
    "- YÃ¼ksek DeÄŸerler (0.7-1): Daha rastgele ve yaratÄ±cÄ± , ancak bazen tutarsÄ±z yanÄ±tlar verebilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b17e7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42ce00c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14574629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d19b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"ğŸ“– Sen, ReÅŸat Nuri GÃ¼ntekinâ€™in *Ã‡alÄ±kuÅŸu* romanÄ± Ã¼zerine uzman, cana yakÄ±n bir edebi asistansÄ±n. \"\n",
    "    \"GÃ¶revin, kÄ±sa ama etkileyici analizler yapmak; karakterleri, temalarÄ± ve duygularÄ± samimi bir dille yorumlamak ğŸ˜Š \"\n",
    "    \"Sadece bu roman hakkÄ±nda konuÅŸ ğŸ›‘ BaÅŸka kitaplardan bahsetme. \"\n",
    "    \"YanÄ±tlarÄ±n TÃ¼rkÃ§e olsun ğŸ‡¹ğŸ‡· ve aÃ§Ä±klamalarÄ±nÄ± emojilerle zenginleÅŸtir ğŸ“Œ\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2dddf731",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        (\"human\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5427ab9",
   "metadata": {},
   "source": [
    "## Soru-Cevap Zinciri OluÅŸturma ( LLM + PROMPT )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d56af7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm,prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57eabb3",
   "metadata": {},
   "source": [
    "## RAG Zinciri OlutÅŸurma ( RAG + LLM )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6260173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68acbdda",
   "metadata": {},
   "source": [
    "## KullanÄ±cÄ± sorgusunu Ã§alÄ±ÅŸtÄ±rma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f27044",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\":\"Peki bu kitabÄ± Ã¶zetlesen nasÄ±l Ã¶zetlersin?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5776c0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer architecture is a model that relies entirely on attention mechanisms, dispensing with recurrence and convolutions. It consists of an encoder and a decoder, both composed of stacks of identical layers. Each encoder layer has a multi-head self-attention mechanism and a position-wise feed-forward network, while each decoder layer includes these plus an additional multi-head attention layer over the encoder's output.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
